%!TEX TS-program = xelatex
\documentclass[12pt, a4paper, oneside]{article}

% Можно вставить разную преамбулу
\input{preamble}

\title{\begin{center} \includegraphics[width=0.99\textwidth]{logo.png} \end{center} Шпаргалка по параметрическим критериям\footnote{Эта pdf-ка, по факту, представляет из себя немного дополненный конспект Бориса Демешева:  \url{https://github.com/bdemeshev/pr201/raw/master/probab_pset/new_el.pdf}}}
\date{ } %\today}

\begin{document} % Конец преамбулы, начало файла

\maketitle

\section{Про единственную выборку}

\subsection*{Математическое ожидание при большом числе наблюдений}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_n$;
    
    \item Предполагаем: $X_i$ независимы и одинаково распределены (не обязательно нормально), количество наблюдений $n$ велико.
    
    \item Проверяемая гипотеза: $H_0$: $\mu = \mu_0$ против $H_a$: $\mu \neq \mu_0$;
    
    \item Статистика:
    \[
    Z = \frac{\bar X - \mu_0}{se(\bar X)} = \frac{\bar X - \mu_0}{\sqrt{\frac{\hat \sigma^2}{n}}}
    \]
    
    \item При верной $H_0$ оказывается, что $Z \to \mN(0;1)$;
\end{enumerate}


\subsection*{Математическое ожидание при нормальных наблюдениях}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_n$;
    
    \item Предполагаем: $X_i$ независимы и одинаково нормально распределены $\mN(\mu; \sigma^2)$, количество наблюдений $n$ может быть мало.
    
    \item Проверяемая гипотеза: $H_0$: $\mu = \mu_0$ против $H_a$: $\mu \neq \mu_0$;
    
    \item Статистика:
    \[
    t = \frac{\bar X - \mu_0}{se(\bar X)} = \frac{\bar X - \mu_0}{\sqrt{\frac{\hat \sigma^2}{n}}}
    \]
    
    \item При верной $H_0$ оказывается, что $t \sim t_{n-1}$;
\end{enumerate}


\subsection*{Математическое ожидание при нормальных наблюдениях и известной дисперсии}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_n$, знаем величину $\sigma^2$;
    
    \item Предполагаем: $X_i$ независимы и одинаково нормально распределены $\mN(\mu; \sigma^2)$, количество наблюдений $n$ может быть мало.
    
    \item Проверяемая гипотеза: $H_0$: $\mu = \mu_0$ против $H_a$: $\mu \neq \mu_0$;
    
    \item Статистика:
    \[
    Z = \frac{\bar X - \mu_0}{\sigma_{\bar X}} = \frac{\bar X - \mu_0}{\sqrt{\frac{\sigma^2}{n}}}
    \]
    
    \item При верной $H_0$ оказывается, что $Z \sim \mN(0;1)$;
\end{enumerate}

\subsection*{Гипотеза о вероятности при наблюдениях с распределением Бернулли (0 или 1)}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_n$;
    
    \item Предполагаем: $X_i$ независимы и имеют распределение Бернулли: равны 1 с вероятностью $p$ и 0 с вероятностью $1-p$. Количество наблюдений $n$ велико.
    
    \item Проверяемая гипотеза: $H_0$: $p = p_0$ против $H_a$: $p \neq p_0$;
    
    \item Статистика:
    \[
    Z = \frac{\hat p - p_0}{se(\hat p)} = \frac{\hat p - p_0}{\sqrt{\frac{\hat p (1- \hat p)}{n}}}
    \]
    Возможен вариант этой статистики:
    
    \[
    Z = \frac{\hat p - p_0}{se(\hat p)} = \frac{\hat p - p_0}{\sqrt{\frac{p_0 (1- p_0 )}{n}}}
    \]
    
    \item При верной $H_0$ оказывается, что $Z \to \mN(0;1)$;
    
    \item Гипотеза о вероятностях является частным случаем гипотезы о математическом ожидании при большом количестве наблюдений. Можно заметить, что $\hat p = \bar X$ и $\hat \sigma^2 = \hat p (1- \hat p) \cdot \frac{n}{n-1}$. И потому также корректен вариант статистики
    
    \[
    Z = \frac{\bar X - \mu_0}{se(\bar X)} = \frac{\bar X - \mu_0}{\sqrt{\frac{\hat \sigma^2}{n}}}
    \]
\end{enumerate}
  
\subsection*{Гипотеза о дисперсии при нормальных наблюдениях}
    
\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_n$;
    
    \item Предполагаем: $X_i$ независимы и одинаково нормально распределены $\mN(\mu; \sigma^2)$, количество наблюдений $n$ может быть мало.
    
    \item Проверяемая гипотеза: $H_0$: $\sigma = \sigma_0$ против $H_a$: $\sigma \neq \sigma_0$;
    
    \item Статистика:
    \[
    S = \frac{\sum (X_i - \bar X)^2}{\sigma_0^2} = \frac{(n-1)\hat\sigma^2}{\sigma_0^2}
    \]
    
    \item При верной $H_0$ оказывается, что $S \sim \chi^2_{n-1}$;
\end{enumerate}

\subsection*{Гипотеза о дисперсии при нормальных наблюдениях и известном математическом ожидании}
    
\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_n$, знаем величину $\mu$;
    
    \item Предполагаем: $X_i$ независимы и одинаково нормально распределены $\mN(\mu; \sigma^2)$, количество наблюдений $n$ может быть мало.
    
    \item Проверяемая гипотеза: $H_0$: $\sigma = \sigma_0$ против $H_a$: $\sigma \neq \sigma_0$;
    
    \item Статистика:
    \[
    S = \frac{\sum (X_i - \bar X)^2}{\sigma_0^2} = \frac{n\hat\sigma^2}{\sigma_0^2}
    \]
    
    \item При верной $H_0$ оказывается, что $S \sim \chi^2_{n}$;
\end{enumerate}

\newpage 

\section{Про пару выборок}

\subsection*{Гипотеза о разнице ожиданий при большом количестве наблюдений}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_{n_x}$, $Y_1$, $Y_2$, \ldots, $Y_{n_y}$.
    
    Возможно, что $n_x \neq n_y$. Дисперсии $\sigma^2_x$ и $\sigma^2_y$ не знаем и не уверены, что они равны.
    
    \item Предполагаем: $X_i$ одинаково распределены между собой (не обязательно нормально),
    $Y_i$ одинаково распределены между собой, но возможно совсем не так, как $X_i$ (не обязательно нормально).
    Все величины независимы. Количества $n_x$ и $n_y$ велики.
    
    \item Проверяемая гипотеза: $H_0$: $\mu_x - \mu_y = \delta_0$ против $H_a$: $\mu_x - \mu_y \neq \delta_0$;
    
    \item Статистика:
    \[
    Z = \frac{\bar X - \bar Y - \delta_0}{se(\bar X - \bar Y)} =
    \frac{\bar X - \bar Y - \delta_0}{\sqrt{\frac{\hat \sigma^2_x}{n_x}+\frac{\hat\sigma^2_y}{n_y}}}
    \]
    
    \item При верной $H_0$ оказывается, что $Z \to \mN(0;1)$;
\end{enumerate}


\subsection*{Гипотеза о разнице ожиданий при нормальности распределения обеих выборок и известных дисперсиях}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_{n_x}$, $Y_1$, $Y_2$, \ldots, $Y_{n_y}$.
    Возможно, что $n_x \neq n_y$. Дисперсии $\sigma^2_x$ и $\sigma^2_y$ знаем. Возможно, что дисперсии не равны.
    
    \item Предполагаем: $X_i$ одинаково распределены между собой $\mN(\mu_x, \sigma^2_x)$,
    $Y_i$ одинаково распределены между собой $\mN(\mu_y, \sigma^2_y)$.
    Все величины независимы. Количества $n_x$ и $n_y$ любые.
    
    \item Проверяемая гипотеза: $H_0$: $\mu_x - \mu_y = \delta_0$ против $H_a$: $\mu_x - \mu_y \neq \delta_0$;
    
    \item Статистика:
    \[
    Z = \frac{\bar X - \bar Y - \delta_0}{\sigma_{\bar X - \bar Y}} =
    \frac{\bar X - \bar Y - \delta_0}{\sqrt{\frac{\sigma^2_x}{n_x}+\frac{\sigma^2_y}{n_y}}}
    \]

    \item При верной $H_0$ оказывается, что $Z \sim \mN(0;1)$;
\end{enumerate}


\subsection*{Гипотеза о разнице ожиданий при нормальности распределения обеих выборок и неизвестных но равных дисперсиях}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_{n_x}$, $Y_1$, $Y_2$, \ldots, $Y_{n_y}$.
    Возможно, что $n_x \neq n_y$. Дисперсии $\sigma^2_x$ и $\sigma^2_y$ равны, но неизвестны.
    
    \item Предполагаем: $X_i$ одинаково распределены между собой $\mN(\mu_x, \sigma^2)$,
    $Y_i$ одинаково распределены между собой $\mN(\mu_y, \sigma^2)$.
    Все величины независимы. Количества $n_x$ и $n_y$ любые.
    
    \item Проверяемая гипотеза: $H_0$: $\mu_x - \mu_y = \delta_0$ против $H_a$: $\mu_x - \mu_y \neq \delta_0$;
    
    \item Статистика:
    \[
    t = \frac{\bar X - \bar Y - \delta_0}{se(\bar X - \bar Y)} =
    \frac{\bar X - \bar Y - \delta_0}{\sqrt{\frac{\hat \sigma^2}{n_x}+\frac{\hat\sigma^2}{n_y}}},
    \]
    где
    \[
    \hat \sigma^2 = \frac{\sum (X_i - \bar X)^2 + \sum (Y_i - \bar Y)^2 }{n_x + n_y - 2}
    \]
    
    \item При верной $H_0$ оказывается, что $t \sim t_{n_x+n_y-2}$;
\end{enumerate}


\subsection*{Гипотеза о разнице ожиданий в связанных парах}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_{n}$, $Y_1$, $Y_2$, \ldots, $Y_{n}$.
    Количество $X_i$ и $Y_i$ одинаковое.
    \item Предполагаем: внутри пары $X_i$ и $Y_i$ зависимы, а наблюдения с разными номерами независимы.
    Рассматриваем разницу $D_i = X_i - Y_i$ и получаем одномерную выборку.
    Величины $D_i$ независимы и одинаково распределены.
    Возможно три описанных ранее случая :)
    Здесь для примера рассмотрим случай, когда $D_i \sim \mN(\mu_d, \sigma^2_d)$ с неизвестной дисперсией.
    
    \item Проверяемая гипотеза: $H_0$: $\mu_d = \mu_0$ против $H_a$: $\mu_d \neq \mu_0$;
    
    \item Статистика:
    \[
    t = \frac{\bar D - \mu_d}{se(\bar D)} =
    \frac{\bar X - \bar Y - \mu_d}{\sqrt{\frac{\hat \sigma^2_d}{n}}},
    \]
    где
    \[
    \hat \sigma^2_d = \frac{\sum (D_i - \bar D)^2 }{n - 1} = \frac{\sum (X_i - Y_i - (\bar X - \bar Y))^2 }{n - 1}
    \]
    
    \item При верной $H_0$ оказывается, что $t \sim t_{n-1}$;
\end{enumerate}

\subsection*{Гипотеза о равенстве дисперсий при нормальности распределения обеих выборок}

\begin{enumerate}
    \item Наблюдаем: $X_1$, $X_2$, \ldots, $X_{n_x}$, $Y_1$, $Y_2$, \ldots, $Y_{n_y}$.
    Возможно, что $n_x \neq n_y$. Дисперсии $\sigma^2_x$ и $\sigma^2_y$ не знаем. Возможно, что дисперсии не равны.
    
    \item Предполагаем: $X_i$ одинаково распределены между собой $\mN(\mu_x, \sigma^2)$,
    $Y_i$ одинаково распределены между собой $\mN(\mu_y, \sigma^2)$.
    Все величины независимы. Количества $n_x$ и $n_y$ любые.
    
    \item Проверяемая гипотеза: $H_0$: $\sigma_x = \sigma_y$ против $H_a$: $\sigma_x \neq \sigma_y$;
    
    \item Статистика:
    \[
    F = \frac{\hat \sigma^2_x}{\hat \sigma^2_y}
    \]
    
    \item При верной $H_0$ оказывается, что $F \sim F_{n_x-1, n_y - 1}$;
\end{enumerate}


\end{document}

